executor: KubernetesExecutor

webserver:
  enabled: true
  replicas: 1

components:
  webserver: true

scheduler:
  enabled: true
  replicas: 1

triggerer:
  enabled: true
  replicas: 1

defaultAirflowRepository: apache/airflow
defaultAirflowTag: "3.0.2"

dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: "https://github.com/samuel-aka-viana/salesforce-mock-orquestration.git"
    branch: "main"
    wait: 60
    subPath: "dags"

ingress:
  web:
    enabled: true
    ingressClassName: "traefik"
    hosts:
      - name: "airflow.local"
        tls:
          enabled: false
    path: "/"
    pathType: "Prefix"

postgresql:
  enabled: true
  primary:
    persistence:
      enabled: true
      storageClass: "local-path"
      size: 5Gi

fernetKeySecretName: "airflow-fernet-key"
fernetKeySecretKey: "fernet-key"

webserverSecretKeySecretName: "airflow-webserver-secret-key"
webserverSecretKey: "webserver-secret-key"

defaultUser:
  enabled: true
  role: Admin
  username: admin
  email: admin@airflow.com
  firstName: Admin
  lastName: User
  password: admin

rbac:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["pods", "pods/log", "pods/exec", "services", "endpoints", "configmaps", "secrets"]
      verbs: ["create", "get", "list", "watch", "delete", "patch", "update"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims"]
      verbs: ["create", "get", "delete"]
    - apiGroups: ["apps"]
      resources: ["deployments"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["batch"]
      resources: ["jobs"]
      verbs: ["create", "get", "list", "watch", "delete"]

serviceAccount:
  create: true
  name: airflow

config:
  core:
    remote_logging: "False"
    execution_api_server_url: "http://airflow-api-server.airflow.svc.cluster.local:8080/execution/"
  api:
    base_url: "http://airflow.local"
    auth_backends: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
  kubernetes_executor:
    namespace: "airflow"
    pod_template_file: ""
    worker_container_repository: "apache/airflow"
    worker_container_tag: "3.0.2"
    delete_worker_pods: "True"
    delete_worker_pods_on_failure: "False"
    worker_container_image_pull_policy: "IfNotPresent"
    multi_namespace_mode: "False"
    worker_service_account_name: "airflow"
    worker_api_server: "http://airflow-api-server.airflow.svc.cluster.local:8080"
  execution:
    task_execution_enabled: "True"
  logging:
    remote_logging: "False"

env:
  - name: AIRFLOW__KUBERNETES__NAMESPACE
    value: "airflow"
  - name: AIRFLOW__KUBERNETES__IN_CLUSTER
    value: "True"
  - name: AIRFLOW__KUBERNETES_EXECUTOR__POD_TEMPLATE_FILE
    value: ""
  - name: AIRFLOW__API__AUTH_BACKENDS
    value: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
  - name: AIRFLOW__EXECUTION__TASK_EXECUTION_ENABLED
    value: "True"
  - name: AIRFLOW__CORE__REMOTE_LOGGING
    value: "False"
  - name: AIRFLOW__LOGGING__REMOTE_LOGGING
    value: "False"
  - name: AIRFLOW__CORE__EXECUTION_API_SERVER_URL
    value: "http://airflow.local/execution/"
  - name: AIRFLOW__API__BASE_URL
    value: "http://airflow.local"
  - name: AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME
    value: "airflow"
  - name: AIRFLOW__KUBERNETES__WORKER_API_SERVER
    value: "http://airflow-api-server.airflow.svc.cluster.local:8080"

podTemplate: |
  apiVersion: v1
  kind: Pod
  metadata:
    name: placeholder-name
    namespace: airflow
  spec:
    serviceAccountName: airflow
    restartPolicy: Never
    volumes:
      - name: dags
        emptyDir: {}
    containers:
      - name: base
        image: apache/airflow:3.0.2
        imagePullPolicy: IfNotPresent
        env:
          - name: AIRFLOW__KUBERNETES__NAMESPACE
            value: "airflow"
          - name: AIRFLOW__KUBERNETES__IN_CLUSTER
            value: "True"
          - name: AIRFLOW__EXECUTION__TASK_EXECUTION_ENABLED
            value: "True"
          - name: AIRFLOW__CORE__REMOTE_LOGGING
            value: "False"
          - name: AIRFLOW__CORE__EXECUTOR
            value: "LocalExecutor"  # Executor dentro do pod worker (padr√£o para K8sExecutor workers)
          - name: AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME
            value: "airflow"
          - name: AIRFLOW__KUBERNETES__WORKER_API_SERVER
            value: "http://airflow-api-server.airflow.svc.cluster.local:8080"
          - name: AIRFLOW__CORE__EXECUTION_API_SERVER_URL
            value: "http://airflow-api-server.airflow.svc.cluster.local:8080/execution/"
          - name: AIRFLOW__API__BASE_URL
            value: "http://airflow-api-server.airflow.svc.cluster.local:8080"
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
        volumeMounts:
          - name: dags
            mountPath: /opt/airflow/dags
            subPath: repo/dags
      - name: git-sync
        image: registry.k8s.io/git-sync/git-sync:v4.2.3
        imagePullPolicy: IfNotPresent
        env:
          - name: GITSYNC_REPO
            value: "https://github.com/samuel-aka-viana/salesforce-mock-orquestration.git"
          - name: GITSYNC_BRANCH
            value: "main"
          - name: GITSYNC_ROOT
            value: /git
          - name: GITSYNC_DEST
            value: "repo"
          - name: GITSYNC_PERIOD
            value: "60s"
          - name: GITSYNC_ONE_TIME
            value: "false"
          - name: GITSYNC_DEPTH
            value: "1"
          - name: GITSYNC_MAX_FAILURES
            value: "0"
        volumeMounts:
          - name: dags
            mountPath: /git
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m" 
            memory: "512Mi"